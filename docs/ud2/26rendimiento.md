# üß† Mejora del rendimiento y buenas pr√°cticas

Optimizar el acceso a BD no va solo de ‚Äúhacer menos queries‚Äù, sino de **gestionar bien las conexiones** y **ejecutar SQL eficientemente**. Estos son los puntos clave:

---

## üîå Conexi√≥n: ¬øsingleton o pool?

üîπ Singleton  
- Patr√≥n de dise√±o que asegura que solo exista **una instancia** de una clase en toda la aplicaci√≥n.

üîπ Pool de conexiones  
- Conjunto de **m√∫ltiples conexiones abiertas** y gestionadas por un `DataSource`.

- ‚ùå **Evita un `Connection` ‚Äúsingleton‚Äù** en aplicaciones con concurrencia:
    - Una `Connection` **no es thread-safe** ‚Üí cuellos de botella y errores.
    - Punto √∫nico de fallo (si cae, cae todo).
    - Conexiones largas pueden caducar o quedar ‚Äúcolgadas‚Äù.

- ‚úÖ **Usa un *pool de conexiones*** (`DataSource`) en su lugar:
    - Reutiliza conexiones abiertas (muy r√°pido).
    - Gestiona caducidad, validaci√≥n, tama√±o del pool y timeouts.
    - Ideal tanto para apps de escritorio con cierta concurrencia como para aplicaciones web.

### Ejemplo con HikariCP (recomendado)

```java
import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import javax.sql.DataSource;

public final class DataSourceSingleton {
    private static final HikariDataSource ds;

    static {
        HikariConfig cfg = new HikariConfig();
        cfg.setJdbcUrl("jdbc:mysql://localhost:3306/severo?useSSL=false");
        cfg.setUsername("patricia");
        cfg.setPassword("marti");

        // Configuraci√≥n del pool
        cfg.setMaximumPoolSize(10);
        cfg.setMinimumIdle(2);
        cfg.setConnectionTimeout(10000); // ms
        cfg.setIdleTimeout(600000);      // ms
        cfg.setMaxLifetime(1800000);     // ms

        ds = new HikariDataSource(cfg);
    }

    private DataSourceSingleton() {}

    public static DataSource getDataSource() { return ds; }
}
```

- Hay un √∫nico HikariDataSource (singleton) por cada origen de datos.  
    - Ese DataSource gestiona internamente un pool de conexiones.  
    - Cada vez que llamas a `getConnection()` de `DataSource`, no abre un socket nuevo:  
       - ‚úÖ Si hay una conexi√≥n libre en el pool ‚Üí te la entrega.  
       - ‚úÖ Si no, crea una nueva hasta llegar al maximumPoolSize.
       - ‚úÖ Cuando cierras la conexi√≥n (try-with-resources), no se destruye, sino que vuelve al pool para reutilizarse. Ese pr√©stamo/devoluci√≥n es muy r√°pido y thread-safe.

Uso:
```java
try (Connection con = DataSourceSingleton.getDataSource().getConnection();
     PreparedStatement ps = con.prepareStatement("SELECT id, user_name FROM login WHERE id < ?")) {

    ps.setInt(1, 10);
    try (ResultSet rs = ps.executeQuery()) {
        while (rs.next()) {
            System.out.println(rs.getInt("id") + " - " + rs.getString("user_name"));
        }
    }
}
```

---

### üì¶ ¬øC√≥mo a√±adir HikariCP?

HikariCP no forma parte de Java SE, hay que a√±adirlo como dependencia externa.

#### Con Maven
```xml
<dependency>
    <groupId>com.zaxxer</groupId>
    <artifactId>HikariCP</artifactId>
    <version>5.1.0</version>
</dependency>
```

#### Con Gradle
```gradle
implementation 'com.zaxxer:HikariCP:5.1.0'
```

#### Manualmente
- Descargar el `.jar` de [Maven Central](https://mvnrepository.com/artifact/com.zaxxer/HikariCP).  
- A√±adirlo al **classpath** del proyecto en IntelliJ/Eclipse.  
- Tambi√©n se necesita el **driver JDBC** de la BD (ej: `mysql-connector-j`).

---

## üßµ Multihilo y conexiones

- Un **hilo ‚â† una conexi√≥n fija**. Pide la conexi√≥n al pool **cuando la necesites** y ci√©rrala lo antes posible.  
- No compartas `Connection`, `Statement` o `ResultSet` entre hilos.  
- Mant√©n las **transacciones cortas** para reducir bloqueos.

---

## ‚öôÔ∏è PreparedStatement y cach√©

- Usa `PreparedStatement` para casi todo tipo de SQL (tambi√©n `SELECT`).  
- Previene **SQL Injection** y mejora el rendimiento gracias al **plan cache** del SGBD.
- Activa la cach√© de prepareds en MySQL con:  
  - `cachePrepStmts=true&prepStmtCacheSize=256&prepStmtCacheSqlLimit=2048`  

---

## üöÄ Inserciones masivas con batch

Para grandes vol√∫menes de datos, agrupa operaciones con `addBatch()`:

```java
String sql = "INSERT INTO login(user_name, password) VALUES (?, ?)";
try (final Connection con = DataSourceSingleton.getDataSource().getConnection();
     PreparedStatement ps = con.prepareStatement(sql)) {

    con.setAutoCommit(false);
    for (Login l : lista) {
        ps.setString(1, l.getUsername());
        ps.setString(2, l.getPassword());
        ps.addBatch();
    }
    ps.executeBatch(); // üöÄ se env√≠a todo junto en un lote
    con.commit();
}
```

---

## üîí Transacciones

- Desactiva `autoCommit` solo cuando necesites agrupar operaciones.  
- Confirma con `commit()` y revierte con `rollback()` en caso de error.  
- Ejemplo:
```java
con.setAutoCommit(false);
try {
    // operaciones SQL
    con.commit();
} catch (SQLException e) {
    con.rollback();
}
```

---

## üßπ Otras buenas pr√°cticas

- Selecciona solo las columnas necesarias (`SELECT columna1, columna2`).
- Usa √≠ndices adecuados en el SGBD.
- Define `setQueryTimeout` para queries largas.
- Cierra siempre recursos en orden: `ResultSet` ‚Üí `Statement` ‚Üí `Connection`. Usa `try-with-resources`.

